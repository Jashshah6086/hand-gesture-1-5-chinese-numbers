{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"plt.ion()  \nimport torch\nprint(torch.cuda.device_count() )\n\n\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    print(\"Using CUDA\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/soc-proj/Data'\nTEST = 'Test'\nTRAIN = 'Train'\nVAL = 'Valid'\n\ndata_transforms = {\n    TRAIN: transforms.Compose([\n        # Data augmentation is a good practice for the train set\n        # Here, we randomly crop the image to 224x224 and\n        # randomly flip it horizontally. \n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.CenterCrop(size=224),  # Image net standards\n        transforms.ToTensor(),\n    ]),\n    VAL: transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(), \n    ]),\n    TEST: transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(size=224),  # Image net standards\n        transforms.ToTensor(), \n    ])\n}\n\nimage_datasets = {\n    x: datasets.ImageFolder(\n        os.path.join(data_dir, x), \n        transform=data_transforms[x]\n    )\n    for x in [TRAIN, VAL, TEST]\n}\n\ndataloaders = {\n    x: torch.utils.data.DataLoader(\n        image_datasets[x], batch_size=8,\n        shuffle=True, num_workers=4\n    )\n    for x in [TRAIN, VAL, TEST]\n}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n\nfor x in [TRAIN, VAL, TEST]:\n    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n    \nprint(\"Classes: \")\nclass_names = image_datasets[TRAIN].classes\nprint(image_datasets[TRAIN].classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    # plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)\n\ndef show_databatch(inputs, classes):\n    out = torchvision.utils.make_grid(inputs)\n    imshow(out, title=[class_names[x%5] for x in classes])\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders[TRAIN]))\nshow_databatch(inputs, classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_model(densenet121, num_images=6):\n    was_training =densenet121.training\n    \n    # Set model for evaluation\n    densenet121.train(False)\n    densenet121.eval() \n    \n    images_so_far = 0\n\n    for i, data in enumerate(dataloaders[TEST]):\n        inputs, labels = data\n        size = inputs.size()[0]\n        \n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n        else:\n            inputs, labels = Variable(inputs), Variable(labels)\n        \n        outputs = densenet121(inputs)\n        \n        _, preds = torch.max(outputs.data, 1)\n        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n        \n        print(\"Ground truth:\")\n        show_databatch(inputs.data.cpu(), labels.data.cpu())\n        print(\"Prediction:\")\n        show_databatch(inputs.data.cpu(), predicted_labels)\n        \n        del inputs, labels, outputs, preds, predicted_labels\n        torch.cuda.empty_cache()\n        \n        images_so_far += size\n        if images_so_far >= num_images:\n            \n            break\n        \n    densenet121.train(mode=was_training) # Revert model back to original training state","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_model(densenet121, criterion):\n    since = time.time()\n    avg_loss = 0.0\n    avg_acc = 0.0\n    loss_test = 0.0\n    acc_test = 0.0\n    \n    test_batches = len(dataloaders[TEST])\n    print(\"Evaluating model\")\n    print('-' * 10)\n    \n    for i, data in enumerate(dataloaders[TEST]):\n        if i % 100 == 0:\n            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n\n        densenet121.train(False)\n        densenet121.eval()\n        inputs, labels = data\n\n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n        else:\n            inputs, labels = Variable(inputs), Variable(labels)\n\n        outputs = densenet121(inputs)\n\n        _, preds = torch.max(outputs.data, 1)\n        loss = criterion(outputs, labels)\n\n        loss_test += loss.data\n        acc_test += torch.sum(preds == labels.data)\n        #print(torch.sum(preds==labels.data), preds==labels.data)\n        \n\n        del inputs, labels, outputs, preds\n        torch.cuda.empty_cache()\n        \n    avg_loss = loss_test / dataset_sizes[TEST]\n    avg_acc = acc_test / dataset_sizes[TEST]\n    print(avg_acc)\n    \n    elapsed_time = time.time() - since\n    print()\n    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n    print('-' * 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vgg16 = models.vgg16_bn()\n# vgg16.load_state_dict(torch.load(\"../input/vgg16bn/vgg16_bn.pth\"))\n# print(vgg16.classifier[6].out_features) # 1000 \n\n\n# # Freeze training for all layers\n# for param in vgg16.features.parameters():\n#     param.require_grad = False\n\n# # Newly created modules have require_grad=True by default\n# num_features = vgg16.classifier[6].in_features\n# features = list(vgg16.classifier.children())[:-1] # Remove last layer\n# features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\n# vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n# print(vgg16)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"densenet121 = models.densenet121()\ndensenet121.load_state_dict(torch.load(\"../input/densenet121/densenet121.pth\"))\n\nfor param in densenet121.parameters():\n    param.require_grad = False\n\n# num_features = resnet34.classifier[6].in_features\n# print(num_features)\nfeatures = list(densenet121.children())[:-1] # Remove last layer\nfeatures.extend([nn.Linear(4096, len(class_names))]) # Add our layer with 4 outputs\ndensenet121.classifier = nn.Sequential(*features) # Replace the model classifier    \n\nprint(densenet121)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resume_training = False\n\n# if resume_training:\n#     print(\"Loading pretrained model..\")\n#     vgg16.load_state_dict(torch.load('../input/vgg16-transfer-learning-pytorch/VGG16_soc.pt'))\n#     print(\"Loaded!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"densenet121.cuda() #.cuda() will move everything to the GPU side\n    \ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(densenet121.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test before training\")\neval_model(densenet121, criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_model(densenet121)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(densenet121, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(densenet121.state_dict())\n    best_acc = 0.0\n    \n    avg_loss = 0.0\n    avg_acc = 0.0\n    avg_loss_val = 0.0\n    avg_acc_val = 0.0\n    \n    train_batches = len(dataloaders[TRAIN])\n    val_batches = len(dataloaders[VAL])\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n        print('-' * 10)\n        \n        loss_train = 0.0\n        loss_val = 0.0\n        acc_train = 0.0\n        acc_val = 0.0\n        \n        densenet121.train(True)\n        \n        for i, data in enumerate(dataloaders[TRAIN]):\n            if i % 100 == 0:\n                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n                \n            # Use half training dataset\n            if i >= train_batches / 2:\n                break\n                \n            inputs, labels = data\n            \n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n            else:\n                inputs, labels = Variable(inputs), Variable(labels)\n            \n            optimizer.zero_grad()\n            \n            outputs = densenet121(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            loss_train += loss.data\n            acc_train += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        print()\n        # * 2 as we only used half of the dataset\n        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n        \n        densenet121.train(False)\n        densenet121.eval()\n            \n        for i, data in enumerate(dataloaders[VAL]):\n            if i % 100 == 0:\n                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n                \n            inputs, labels = data\n            \n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n            else:\n                inputs, labels = Variable(inputs), Variable(labels)\n            \n            optimizer.zero_grad()\n            \n            outputs = densenet121(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss_val += loss.data\n            acc_val += torch.sum(preds == labels.data)\n            \n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        avg_loss_val = loss_val / dataset_sizes[VAL]\n        avg_acc_val = acc_val / dataset_sizes[VAL]\n        \n        print()\n        print(\"Epoch {} result: \".format(epoch))\n        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n        print('-' * 10)\n        print()\n        \n        if avg_acc_val > best_acc:\n            best_acc = avg_acc_val\n            best_model_wts = copy.deepcopy(densenet121.state_dict())\n        \n    elapsed_time = time.time() - since\n    print()\n    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Best acc: {:.4f}\".format(best_acc))\n    \n    densenet121.load_state_dict(best_model_wts)\n    return densenet121","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"densenet121 = train_model(densenet121, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)\n# torch.save(resnet34.state_dict(), 'VGG16_soc.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_model(densenet121, criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_model(densenet121, num_images=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
